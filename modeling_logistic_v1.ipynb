{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a244517f-e8bd-40db-8c90-b1de9fcd2848",
   "metadata": {},
   "source": [
    "# Logistic Regression and Random Forest to Predict Arrival Delay of 15+ Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e9bb51b-0a7d-4ce9-ba86-6d834d73b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline  \n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.sql.functions import when\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af1075cc-9224-4376-af9c-7838fe6d6aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/12/01 02:44:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd4fa66-0509-48c3-8005-16c6659ef834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training years\n",
    "flights_2018 = spark.read.parquet('/standard/ds7200-apt4c/isaac_yuyang_final_project/flights_2018.parquet')\n",
    "flights_2019 = spark.read.parquet('/standard/ds7200-apt4c/isaac_yuyang_final_project/flights_2019.parquet')\n",
    "flights_2020 = spark.read.parquet('/standard/ds7200-apt4c/isaac_yuyang_final_project/flights_2020.parquet')\n",
    "flights_2021 = spark.read.parquet('/standard/ds7200-apt4c/isaac_yuyang_final_project/flights_2021.parquet')\n",
    "# Test year\n",
    "flights_2022 = spark.read.parquet('/standard/ds7200-apt4c/isaac_yuyang_final_project/flights_2022.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0deade64-11f3-41a4-ba50-b2cd35ebd504",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = flights_2018.union(flights_2019).union(flights_2020).union(flights_2021)\n",
    "train = combined.select(['Airline', 'DayOfWeek', 'DayofMonth', 'Month', 'DepDelay', 'TaxiOut', 'Distance', 'Origin', 'Dest', 'ArrDel15']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a093e73c-5342-471b-b379-0059fd756f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "24394688"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a85194fc-5ffd-45a8-a838-84691dbc1ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "14637535"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample = train.sample(fraction=0.6, seed=59)\n",
    "train_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e3c3ed2-0e41-4b87-9f23-e1ff330857a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "3944916"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean test set\n",
    "test = flights_2022.select(['Airline', 'DayOfWeek', 'DayofMonth', 'Month', 'DepDelay', 'TaxiOut', 'Distance', 'Origin', 'Dest', 'ArrDel15']).dropna()\n",
    "test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb318e-1af2-4bc8-81ec-4c7d0cac1570",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28170fee-4a5a-425d-94d5-885838b771e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline stages\n",
    "indexer_airline = StringIndexer(inputCol='Airline', outputCol='airline_index')\n",
    "indexer_origin = StringIndexer(inputCol='Origin', outputCol='origin_index')\n",
    "indexer_dest = StringIndexer(inputCol='Dest', outputCol='dest_index')\n",
    "indexer_dow = StringIndexer(inputCol='DayOfWeek', outputCol='dow_index')\n",
    "indexer_dom = StringIndexer(inputCol='DayofMonth', outputCol='dom_index')\n",
    "\n",
    "ohe = OneHotEncoder(inputCols=['airline_index', 'origin_index', 'dest_index', 'dow_index', 'dom_index'], outputCols=['airline_ohe', 'origin_ohe', 'dest_ohe', 'dow_ohe', 'dom_ohe'])\n",
    "\n",
    "#va = VectorAssembler(inputCols=['airline_ohe', 'dow_ohe', 'dom_ohe', 'DepDelay', 'TaxiOut', 'Distance'], outputCol='features')\n",
    "va = VectorAssembler(inputCols=['airline_ohe', 'origin_ohe', 'dest_ohe', 'dow_ohe', 'dom_ohe', 'Month', 'TaxiOut', 'Distance'], outputCol='features')\n",
    "\n",
    "sc = StandardScaler(inputCol='features', outputCol='scaledFeatures')\n",
    "lr = LogisticRegression(labelCol='ArrDel15', featuresCol='scaledFeatures', maxIter=50)\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer_airline, indexer_origin, indexer_dest, indexer_dow, indexer_dom, ohe, va, sc, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3460605-dace-44e5-9661-5de2f13a00e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f703d5f7-763a-413b-a2b6-2af5f27aa187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 313:=================================================>       (7 + 1) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC: 0.5454443091829165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                          labelCol='ArrDel15',\n",
    "                                          metricName='areaUnderROC')\n",
    "auroc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f'Area under ROC: {auroc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4004a379-16c1-4cf7-bd62-cbe6cdea2fab",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62a74ed8-f7b3-4b3a-8fb3-280a5a82c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline stages\n",
    "indexer_airline = StringIndexer(inputCol='Airline', outputCol='airline_index')\n",
    "indexer_origin = StringIndexer(inputCol='Origin', outputCol='origin_index')\n",
    "indexer_dest = StringIndexer(inputCol='Dest', outputCol='dest_index')\n",
    "indexer_dow = StringIndexer(inputCol='DayOfWeek', outputCol='dow_index')\n",
    "indexer_dom = StringIndexer(inputCol='DayofMonth', outputCol='dom_index')\n",
    "\n",
    "ohe = OneHotEncoder(inputCols=['airline_index', 'origin_index', 'dest_index', 'dow_index', 'dom_index'], outputCols=['airline_ohe', 'origin_ohe', 'dest_ohe', 'dow_ohe', 'dom_ohe'])\n",
    "\n",
    "#va = VectorAssembler(inputCols=['airline_ohe', 'dow_ohe', 'dom_ohe', 'DepDelay', 'TaxiOut', 'Distance'], outputCol='features')\n",
    "va = VectorAssembler(inputCols=['airline_ohe', 'origin_ohe', 'dest_ohe', 'dow_ohe', 'dom_ohe', 'Month', 'TaxiOut', 'Distance'], outputCol='features')\n",
    "\n",
    "rf = RandomForestClassifier(labelCol='ArrDel15', featuresCol='features', numTrees=50)\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer_airline, indexer_origin, indexer_dest, indexer_dow, indexer_dom, ohe, va, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e405a598-1fdc-412a-9fde-cf2a262023fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 347:================================================>      (28 + 4) / 32]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/12/01 02:55:44 WARN MemoryStore: Not enough space to cache rdd_1301_11 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 02:55:44 WARN BlockManager: Persisting block rdd_1301_11 to disk instead.\n",
      "25/12/01 02:55:44 WARN MemoryStore: Not enough space to cache rdd_1301_19 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 02:55:44 WARN BlockManager: Persisting block rdd_1301_19 to disk instead.\n",
      "25/12/01 02:55:44 WARN MemoryStore: Not enough space to cache rdd_1301_27 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 02:55:44 WARN BlockManager: Persisting block rdd_1301_27 to disk instead.\n",
      "25/12/01 02:56:08 WARN MemoryStore: Not enough space to cache rdd_1301_3 in memory! (computed 6.6 GiB so far)\n",
      "25/12/01 02:56:08 WARN BlockManager: Persisting block rdd_1301_3 to disk instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 347:================================================>      (28 + 4) / 32]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/12/01 02:56:53 WARN MemoryStore: Not enough space to cache rdd_1301_19 in memory! (computed 6.6 GiB so far)\n",
      "25/12/01 02:56:55 WARN MemoryStore: Not enough space to cache rdd_1301_3 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 02:57:05 WARN MemoryStore: Not enough space to cache rdd_1301_27 in memory! (computed 2014.7 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 347:===================================================>   (30 + 2) / 32]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/12/01 02:57:38 WARN MemoryStore: Not enough space to cache rdd_1301_11 in memory! (computed 6.6 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 349:================================================>      (28 + 4) / 32]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/12/01 02:58:26 WARN MemoryStore: Not enough space to cache rdd_1301_11 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 02:58:26 WARN MemoryStore: Not enough space to cache rdd_1301_19 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 02:58:26 WARN MemoryStore: Not enough space to cache rdd_1301_27 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 02:58:28 WARN MemoryStore: Not enough space to cache rdd_1301_3 in memory! (computed 3.0 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 351:================================================>      (28 + 4) / 32]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/12/01 02:59:30 WARN MemoryStore: Not enough space to cache rdd_1301_11 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 02:59:30 WARN MemoryStore: Not enough space to cache rdd_1301_19 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 02:59:31 WARN MemoryStore: Not enough space to cache rdd_1301_27 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 02:59:32 WARN MemoryStore: Not enough space to cache rdd_1301_3 in memory! (computed 3.0 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 353:================================================>      (28 + 4) / 32]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/12/01 03:00:42 WARN MemoryStore: Not enough space to cache rdd_1301_11 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 03:00:42 WARN MemoryStore: Not enough space to cache rdd_1301_19 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 03:00:42 WARN MemoryStore: Not enough space to cache rdd_1301_27 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 03:00:43 WARN MemoryStore: Not enough space to cache rdd_1301_3 in memory! (computed 3.0 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 355:================================================>      (28 + 4) / 32]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/12/01 03:02:04 WARN MemoryStore: Not enough space to cache rdd_1301_11 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 03:02:04 WARN MemoryStore: Not enough space to cache rdd_1301_19 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 03:02:04 WARN MemoryStore: Not enough space to cache rdd_1301_27 in memory! (computed 2014.7 MiB so far)\n",
      "25/12/01 03:02:06 WARN MemoryStore: Not enough space to cache rdd_1301_3 in memory! (computed 3.0 GiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0df4659-29c5-4e3f-9eb0-4c9530b36930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 357:=================================================>       (7 + 1) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                          labelCol='ArrDel15',\n",
    "                                          metricName='areaUnderROC')\n",
    "auroc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f'Area under ROC: {auroc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ad83dfe-49d9-4fe5-911d-0199f0a3d1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9557306025332492"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = combined.stat.corr('DepDelay', 'ArrDelay')\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd6be8-eac6-40d1-aeb9-df404ec8cb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS7200 Spark 3.3",
   "language": "python",
   "name": "ds5110_spark3.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
